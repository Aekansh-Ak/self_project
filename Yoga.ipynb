{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yfMknaVWwkA0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iw5_D5gbxHvD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEPp3EDsxJS7",
    "outputId": "98a465cf-3c66-442c-9443-a6ebf591ccd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "chqIK-hBxLey"
   },
   "outputs": [],
   "source": [
    "#Numpy array conversion in Yoga_pose\n",
    "X_train=np.load('/content/drive/MyDrive/yoga/X_train.npy')\n",
    "X_test=np.load('/content/drive/MyDrive/yoga/X_test.npy')\n",
    "y_train=np.load('/content/drive/MyDrive/yoga/y_train.npy')\n",
    "y_test=np.load('/content/drive/MyDrive/yoga/y_test.npy')\n",
    "y_to_check=np.load('/content/drive/MyDrive/yoga/y_to_check.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bG1Z9NtLCEK8"
   },
   "outputs": [],
   "source": [
    "#Normailizing the numpy array, both methods are fine.\n",
    "\n",
    "# X_train=tf.keras.applications.resnet50.preprocess_input(X_train)\n",
    "# X_test=tf.keras.applications.resnet50.preprocess_input(X_test)\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e4YEpUaOVpgm"
   },
   "outputs": [],
   "source": [
    "# resize_and_rescale = tf.keras.Sequential([\n",
    "#   layers.experimental.preprocessing.Resizing(224,224),\n",
    "#   layers.experimental.preprocessing.Rescaling(1./255),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HSge5aGnJg6S"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation to counter Overfitting\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "  layers.RandomZoom(0.2),\n",
    "  layers.RandomContrast(0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yNd7gFzfyqv2"
   },
   "outputs": [],
   "source": [
    "#ResNet 152 for transfer Learning\n",
    "base_model = tf.keras.applications.ResNet152(weights = 'imagenet',include_top = False, input_shape = (224,224,3))\n",
    "\n",
    "#Unfreeze the layers so the model can learn weights according to the dataset.\n",
    "# for layer in base_model.layers:\n",
    "#   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Le57m7Ek-PRh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense1= layers.Dense(1000, activation='relu')\n",
    "drop1= layers.Dropout(0.4)\n",
    "dense2= layers.Dense(1000, activation='relu')\n",
    "drop2= layers.Dropout(0.4)\n",
    "prediction_layer = layers.Dense(37, activation='softmax')\n",
    "\n",
    "\n",
    "base_model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense1,\n",
    "    drop1,\n",
    "    dense2,\n",
    "    drop2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uGhtz5DE-lrN"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "base_model.compile(optimizer=optim, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5uCgjAk79wE5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pvA5mEBXARHX"
   },
   "outputs": [],
   "source": [
    "#Defining a function to stop training when val_accuracy raches a certain threshold\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        accuracy = logs[\"val_accuracy\"]\n",
    "        if accuracy >= self.threshold:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DtikPG7AAXuB"
   },
   "outputs": [],
   "source": [
    "callback=MyThresholdCallback(threshold=0.74) #train until val_accuracy is not 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PY9jJsyY7EEs",
    "outputId": "9b680cfb-7b3d-4528-9b47-3413d9bd2b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "38/38 - 44s - loss: 5.1311 - accuracy: 0.0554 - val_loss: 3.6955 - val_accuracy: 0.0264 - 44s/epoch - 1s/step\n",
      "Epoch 2/150\n",
      "38/38 - 17s - loss: 3.4648 - accuracy: 0.1017 - val_loss: 3.6100 - val_accuracy: 0.0264 - 17s/epoch - 460ms/step\n",
      "Epoch 3/150\n",
      "38/38 - 17s - loss: 3.1648 - accuracy: 0.1671 - val_loss: 3.6023 - val_accuracy: 0.0231 - 17s/epoch - 460ms/step\n",
      "Epoch 4/150\n",
      "38/38 - 17s - loss: 2.8623 - accuracy: 0.2250 - val_loss: 3.7419 - val_accuracy: 0.0363 - 17s/epoch - 460ms/step\n",
      "Epoch 5/150\n",
      "38/38 - 18s - loss: 2.6045 - accuracy: 0.3077 - val_loss: 4.1127 - val_accuracy: 0.0198 - 18s/epoch - 461ms/step\n",
      "Epoch 6/150\n",
      "38/38 - 17s - loss: 2.2820 - accuracy: 0.3763 - val_loss: 3.8668 - val_accuracy: 0.0132 - 17s/epoch - 460ms/step\n",
      "Epoch 7/150\n",
      "38/38 - 17s - loss: 2.1128 - accuracy: 0.4103 - val_loss: 4.0856 - val_accuracy: 0.0363 - 17s/epoch - 460ms/step\n",
      "Epoch 8/150\n",
      "38/38 - 17s - loss: 1.7469 - accuracy: 0.5004 - val_loss: 4.0486 - val_accuracy: 0.0363 - 17s/epoch - 460ms/step\n",
      "Epoch 9/150\n",
      "38/38 - 17s - loss: 1.5894 - accuracy: 0.5567 - val_loss: 4.1258 - val_accuracy: 0.0396 - 17s/epoch - 460ms/step\n",
      "Epoch 10/150\n",
      "38/38 - 17s - loss: 1.4591 - accuracy: 0.5864 - val_loss: 4.1075 - val_accuracy: 0.0363 - 17s/epoch - 460ms/step\n",
      "Epoch 11/150\n",
      "38/38 - 17s - loss: 1.2336 - accuracy: 0.6427 - val_loss: 3.4761 - val_accuracy: 0.1254 - 17s/epoch - 459ms/step\n",
      "Epoch 12/150\n",
      "38/38 - 17s - loss: 1.1417 - accuracy: 0.6749 - val_loss: 3.6061 - val_accuracy: 0.1089 - 17s/epoch - 460ms/step\n",
      "Epoch 13/150\n",
      "38/38 - 17s - loss: 1.0876 - accuracy: 0.6816 - val_loss: 3.4040 - val_accuracy: 0.1683 - 17s/epoch - 460ms/step\n",
      "Epoch 14/150\n",
      "38/38 - 17s - loss: 0.9219 - accuracy: 0.7138 - val_loss: 3.6218 - val_accuracy: 0.1386 - 17s/epoch - 460ms/step\n",
      "Epoch 15/150\n",
      "38/38 - 18s - loss: 0.8905 - accuracy: 0.7568 - val_loss: 3.5282 - val_accuracy: 0.1650 - 18s/epoch - 461ms/step\n",
      "Epoch 16/150\n",
      "38/38 - 18s - loss: 0.7966 - accuracy: 0.7676 - val_loss: 3.0213 - val_accuracy: 0.2574 - 18s/epoch - 461ms/step\n",
      "Epoch 17/150\n",
      "38/38 - 18s - loss: 0.7830 - accuracy: 0.7800 - val_loss: 2.3207 - val_accuracy: 0.4059 - 18s/epoch - 461ms/step\n",
      "Epoch 18/150\n",
      "38/38 - 17s - loss: 0.6529 - accuracy: 0.8015 - val_loss: 2.0022 - val_accuracy: 0.5248 - 17s/epoch - 460ms/step\n",
      "Epoch 19/150\n",
      "38/38 - 17s - loss: 0.6318 - accuracy: 0.8156 - val_loss: 1.8000 - val_accuracy: 0.5776 - 17s/epoch - 460ms/step\n",
      "Epoch 20/150\n",
      "38/38 - 17s - loss: 0.5528 - accuracy: 0.8379 - val_loss: 1.5595 - val_accuracy: 0.5908 - 17s/epoch - 460ms/step\n",
      "Epoch 21/150\n",
      "38/38 - 17s - loss: 0.5094 - accuracy: 0.8420 - val_loss: 1.7878 - val_accuracy: 0.5545 - 17s/epoch - 460ms/step\n",
      "Epoch 22/150\n",
      "38/38 - 17s - loss: 0.5267 - accuracy: 0.8519 - val_loss: 1.8087 - val_accuracy: 0.5677 - 17s/epoch - 460ms/step\n",
      "Epoch 23/150\n",
      "38/38 - 17s - loss: 0.5420 - accuracy: 0.8362 - val_loss: 1.7512 - val_accuracy: 0.5743 - 17s/epoch - 460ms/step\n",
      "Epoch 24/150\n",
      "38/38 - 17s - loss: 0.5494 - accuracy: 0.8445 - val_loss: 1.6124 - val_accuracy: 0.6304 - 17s/epoch - 460ms/step\n",
      "Epoch 25/150\n",
      "38/38 - 17s - loss: 0.4635 - accuracy: 0.8668 - val_loss: 1.4759 - val_accuracy: 0.6766 - 17s/epoch - 460ms/step\n",
      "Epoch 26/150\n",
      "38/38 - 18s - loss: 0.4138 - accuracy: 0.8710 - val_loss: 1.3474 - val_accuracy: 0.6832 - 18s/epoch - 461ms/step\n",
      "Epoch 27/150\n",
      "38/38 - 17s - loss: 0.4644 - accuracy: 0.8610 - val_loss: 1.7582 - val_accuracy: 0.6238 - 17s/epoch - 460ms/step\n",
      "Epoch 28/150\n",
      "38/38 - 17s - loss: 0.4031 - accuracy: 0.8784 - val_loss: 1.2907 - val_accuracy: 0.7030 - 17s/epoch - 460ms/step\n",
      "Epoch 29/150\n",
      "38/38 - 18s - loss: 0.3348 - accuracy: 0.8991 - val_loss: 1.3446 - val_accuracy: 0.7228 - 18s/epoch - 461ms/step\n",
      "Epoch 30/150\n",
      "38/38 - 17s - loss: 0.3107 - accuracy: 0.9148 - val_loss: 1.5784 - val_accuracy: 0.7063 - 17s/epoch - 460ms/step\n",
      "Epoch 31/150\n",
      "38/38 - 17s - loss: 0.3528 - accuracy: 0.9049 - val_loss: 1.0949 - val_accuracy: 0.7228 - 17s/epoch - 459ms/step\n",
      "Epoch 32/150\n",
      "38/38 - 17s - loss: 0.2549 - accuracy: 0.9198 - val_loss: 1.2312 - val_accuracy: 0.7492 - 17s/epoch - 460ms/step\n",
      "Epoch 33/150\n",
      "38/38 - 17s - loss: 0.2735 - accuracy: 0.9231 - val_loss: 1.5615 - val_accuracy: 0.6535 - 17s/epoch - 460ms/step\n",
      "Epoch 34/150\n",
      "38/38 - 17s - loss: 0.2671 - accuracy: 0.9214 - val_loss: 1.7872 - val_accuracy: 0.6832 - 17s/epoch - 460ms/step\n",
      "Epoch 35/150\n",
      "38/38 - 17s - loss: 0.2954 - accuracy: 0.9214 - val_loss: 1.5133 - val_accuracy: 0.7129 - 17s/epoch - 460ms/step\n",
      "Epoch 36/150\n",
      "38/38 - 17s - loss: 0.2631 - accuracy: 0.9289 - val_loss: 1.6528 - val_accuracy: 0.6304 - 17s/epoch - 460ms/step\n",
      "Epoch 37/150\n",
      "38/38 - 17s - loss: 0.3236 - accuracy: 0.9065 - val_loss: 1.5226 - val_accuracy: 0.6304 - 17s/epoch - 460ms/step\n",
      "Epoch 38/150\n",
      "38/38 - 18s - loss: 0.2725 - accuracy: 0.9189 - val_loss: 1.4577 - val_accuracy: 0.6634 - 18s/epoch - 461ms/step\n",
      "Epoch 39/150\n",
      "38/38 - 18s - loss: 0.2306 - accuracy: 0.9380 - val_loss: 1.5773 - val_accuracy: 0.6436 - 18s/epoch - 461ms/step\n",
      "Epoch 40/150\n",
      "38/38 - 18s - loss: 0.1967 - accuracy: 0.9330 - val_loss: 2.1535 - val_accuracy: 0.6040 - 18s/epoch - 462ms/step\n",
      "Epoch 41/150\n",
      "38/38 - 17s - loss: 0.2468 - accuracy: 0.9338 - val_loss: 1.9959 - val_accuracy: 0.6469 - 17s/epoch - 460ms/step\n",
      "Epoch 42/150\n",
      "38/38 - 17s - loss: 0.1905 - accuracy: 0.9454 - val_loss: 1.5172 - val_accuracy: 0.7195 - 17s/epoch - 460ms/step\n",
      "Epoch 43/150\n",
      "38/38 - 18s - loss: 0.2118 - accuracy: 0.9454 - val_loss: 1.8064 - val_accuracy: 0.6370 - 18s/epoch - 461ms/step\n",
      "Epoch 44/150\n",
      "38/38 - 17s - loss: 0.1799 - accuracy: 0.9529 - val_loss: 1.4688 - val_accuracy: 0.6898 - 17s/epoch - 460ms/step\n",
      "Epoch 45/150\n",
      "38/38 - 18s - loss: 0.1298 - accuracy: 0.9611 - val_loss: 1.4902 - val_accuracy: 0.7129 - 18s/epoch - 462ms/step\n",
      "Epoch 46/150\n",
      "38/38 - 17s - loss: 0.1254 - accuracy: 0.9578 - val_loss: 1.8641 - val_accuracy: 0.6601 - 17s/epoch - 460ms/step\n",
      "Epoch 47/150\n",
      "38/38 - 17s - loss: 0.1797 - accuracy: 0.9553 - val_loss: 2.2022 - val_accuracy: 0.6502 - 17s/epoch - 460ms/step\n",
      "Epoch 48/150\n",
      "38/38 - 17s - loss: 0.1494 - accuracy: 0.9545 - val_loss: 1.7833 - val_accuracy: 0.6601 - 17s/epoch - 460ms/step\n",
      "Epoch 49/150\n",
      "38/38 - 17s - loss: 0.1445 - accuracy: 0.9520 - val_loss: 1.7253 - val_accuracy: 0.6733 - 17s/epoch - 460ms/step\n",
      "Epoch 50/150\n",
      "38/38 - 18s - loss: 0.2199 - accuracy: 0.9413 - val_loss: 2.0641 - val_accuracy: 0.6205 - 18s/epoch - 461ms/step\n",
      "Epoch 51/150\n",
      "38/38 - 18s - loss: 0.3124 - accuracy: 0.9173 - val_loss: 2.0037 - val_accuracy: 0.6502 - 18s/epoch - 461ms/step\n",
      "Epoch 52/150\n",
      "38/38 - 17s - loss: 0.2486 - accuracy: 0.9330 - val_loss: 1.9182 - val_accuracy: 0.6601 - 17s/epoch - 460ms/step\n",
      "Epoch 53/150\n",
      "38/38 - 17s - loss: 0.1911 - accuracy: 0.9404 - val_loss: 1.9986 - val_accuracy: 0.6304 - 17s/epoch - 460ms/step\n",
      "Epoch 54/150\n",
      "38/38 - 18s - loss: 0.1735 - accuracy: 0.9454 - val_loss: 2.3142 - val_accuracy: 0.6370 - 18s/epoch - 461ms/step\n",
      "Epoch 55/150\n",
      "38/38 - 18s - loss: 0.1748 - accuracy: 0.9529 - val_loss: 2.1695 - val_accuracy: 0.6469 - 18s/epoch - 461ms/step\n",
      "Epoch 56/150\n",
      "38/38 - 17s - loss: 0.1493 - accuracy: 0.9529 - val_loss: 1.5679 - val_accuracy: 0.7129 - 17s/epoch - 460ms/step\n",
      "Epoch 57/150\n",
      "38/38 - 18s - loss: 0.1700 - accuracy: 0.9512 - val_loss: 2.0391 - val_accuracy: 0.6667 - 18s/epoch - 461ms/step\n",
      "Epoch 58/150\n",
      "38/38 - 18s - loss: 0.2079 - accuracy: 0.9479 - val_loss: 1.9425 - val_accuracy: 0.6766 - 18s/epoch - 461ms/step\n",
      "Epoch 59/150\n",
      "38/38 - 17s - loss: 0.1918 - accuracy: 0.9438 - val_loss: 1.9166 - val_accuracy: 0.6568 - 17s/epoch - 460ms/step\n",
      "Epoch 60/150\n",
      "38/38 - 17s - loss: 0.2186 - accuracy: 0.9380 - val_loss: 1.9108 - val_accuracy: 0.6799 - 17s/epoch - 460ms/step\n",
      "Epoch 61/150\n",
      "38/38 - 17s - loss: 0.1200 - accuracy: 0.9669 - val_loss: 1.9639 - val_accuracy: 0.7030 - 17s/epoch - 460ms/step\n",
      "Epoch 62/150\n",
      "38/38 - 17s - loss: 0.1013 - accuracy: 0.9719 - val_loss: 2.2059 - val_accuracy: 0.6931 - 17s/epoch - 460ms/step\n",
      "Epoch 63/150\n",
      "38/38 - 17s - loss: 0.0857 - accuracy: 0.9752 - val_loss: 1.9771 - val_accuracy: 0.6931 - 17s/epoch - 460ms/step\n",
      "Epoch 64/150\n",
      "38/38 - 17s - loss: 0.1648 - accuracy: 0.9611 - val_loss: 1.8203 - val_accuracy: 0.6931 - 17s/epoch - 460ms/step\n",
      "Epoch 65/150\n",
      "38/38 - 17s - loss: 0.1881 - accuracy: 0.9471 - val_loss: 2.8365 - val_accuracy: 0.5842 - 17s/epoch - 460ms/step\n",
      "Epoch 66/150\n",
      "38/38 - 17s - loss: 0.2599 - accuracy: 0.9272 - val_loss: 2.4464 - val_accuracy: 0.5644 - 17s/epoch - 460ms/step\n",
      "Epoch 67/150\n",
      "38/38 - 17s - loss: 0.2388 - accuracy: 0.9380 - val_loss: 2.0243 - val_accuracy: 0.6139 - 17s/epoch - 460ms/step\n",
      "Epoch 68/150\n",
      "38/38 - 17s - loss: 0.1736 - accuracy: 0.9454 - val_loss: 2.4383 - val_accuracy: 0.6073 - 17s/epoch - 460ms/step\n",
      "Epoch 69/150\n",
      "38/38 - 17s - loss: 0.1568 - accuracy: 0.9603 - val_loss: 2.3532 - val_accuracy: 0.6502 - 17s/epoch - 460ms/step\n",
      "Epoch 70/150\n",
      "38/38 - 17s - loss: 0.1949 - accuracy: 0.9454 - val_loss: 2.4337 - val_accuracy: 0.5710 - 17s/epoch - 459ms/step\n",
      "Epoch 71/150\n",
      "38/38 - 17s - loss: 0.1514 - accuracy: 0.9537 - val_loss: 2.0271 - val_accuracy: 0.6766 - 17s/epoch - 459ms/step\n",
      "Epoch 72/150\n",
      "38/38 - 17s - loss: 0.1638 - accuracy: 0.9520 - val_loss: 2.2483 - val_accuracy: 0.6568 - 17s/epoch - 459ms/step\n",
      "Epoch 73/150\n",
      "38/38 - 17s - loss: 0.1268 - accuracy: 0.9603 - val_loss: 2.4639 - val_accuracy: 0.6073 - 17s/epoch - 459ms/step\n",
      "Epoch 74/150\n",
      "38/38 - 17s - loss: 0.1184 - accuracy: 0.9686 - val_loss: 2.2561 - val_accuracy: 0.6733 - 17s/epoch - 460ms/step\n",
      "Epoch 75/150\n",
      "38/38 - 17s - loss: 0.0958 - accuracy: 0.9702 - val_loss: 2.0518 - val_accuracy: 0.6799 - 17s/epoch - 459ms/step\n",
      "Epoch 76/150\n",
      "38/38 - 17s - loss: 0.1322 - accuracy: 0.9669 - val_loss: 1.9188 - val_accuracy: 0.6436 - 17s/epoch - 458ms/step\n",
      "Epoch 77/150\n",
      "38/38 - 17s - loss: 0.0975 - accuracy: 0.9727 - val_loss: 3.1708 - val_accuracy: 0.5248 - 17s/epoch - 460ms/step\n",
      "Epoch 78/150\n",
      "38/38 - 17s - loss: 0.1034 - accuracy: 0.9711 - val_loss: 2.4804 - val_accuracy: 0.6304 - 17s/epoch - 459ms/step\n",
      "Epoch 79/150\n",
      "38/38 - 17s - loss: 0.1895 - accuracy: 0.9628 - val_loss: 2.1393 - val_accuracy: 0.6733 - 17s/epoch - 458ms/step\n",
      "Epoch 80/150\n",
      "38/38 - 17s - loss: 0.1227 - accuracy: 0.9653 - val_loss: 2.3645 - val_accuracy: 0.6304 - 17s/epoch - 460ms/step\n",
      "Epoch 81/150\n",
      "38/38 - 17s - loss: 0.1516 - accuracy: 0.9611 - val_loss: 2.0965 - val_accuracy: 0.6271 - 17s/epoch - 459ms/step\n",
      "Epoch 82/150\n",
      "38/38 - 17s - loss: 0.1902 - accuracy: 0.9462 - val_loss: 1.7891 - val_accuracy: 0.6634 - 17s/epoch - 460ms/step\n",
      "Epoch 83/150\n",
      "38/38 - 17s - loss: 0.1709 - accuracy: 0.9570 - val_loss: 1.9655 - val_accuracy: 0.6469 - 17s/epoch - 459ms/step\n",
      "Epoch 84/150\n",
      "38/38 - 17s - loss: 0.1550 - accuracy: 0.9537 - val_loss: 2.3543 - val_accuracy: 0.6040 - 17s/epoch - 459ms/step\n",
      "Epoch 85/150\n",
      "38/38 - 17s - loss: 0.1208 - accuracy: 0.9611 - val_loss: 2.1310 - val_accuracy: 0.6403 - 17s/epoch - 460ms/step\n",
      "Epoch 86/150\n",
      "38/38 - 17s - loss: 0.1148 - accuracy: 0.9661 - val_loss: 2.0507 - val_accuracy: 0.6832 - 17s/epoch - 459ms/step\n",
      "Epoch 87/150\n",
      "38/38 - 17s - loss: 0.1240 - accuracy: 0.9702 - val_loss: 2.0281 - val_accuracy: 0.6370 - 17s/epoch - 460ms/step\n",
      "Epoch 88/150\n",
      "38/38 - 17s - loss: 0.1657 - accuracy: 0.9620 - val_loss: 1.8907 - val_accuracy: 0.6601 - 17s/epoch - 459ms/step\n",
      "Epoch 89/150\n",
      "38/38 - 17s - loss: 0.1476 - accuracy: 0.9578 - val_loss: 1.8499 - val_accuracy: 0.6535 - 17s/epoch - 459ms/step\n",
      "Epoch 90/150\n",
      "38/38 - 17s - loss: 0.1192 - accuracy: 0.9702 - val_loss: 2.0803 - val_accuracy: 0.6337 - 17s/epoch - 459ms/step\n",
      "Epoch 91/150\n",
      "38/38 - 17s - loss: 0.1131 - accuracy: 0.9653 - val_loss: 2.1404 - val_accuracy: 0.6238 - 17s/epoch - 459ms/step\n",
      "Epoch 92/150\n",
      "38/38 - 17s - loss: 0.0717 - accuracy: 0.9810 - val_loss: 1.8999 - val_accuracy: 0.6733 - 17s/epoch - 459ms/step\n",
      "Epoch 93/150\n",
      "38/38 - 17s - loss: 0.0792 - accuracy: 0.9777 - val_loss: 1.8446 - val_accuracy: 0.6832 - 17s/epoch - 459ms/step\n",
      "Epoch 94/150\n",
      "38/38 - 17s - loss: 0.0814 - accuracy: 0.9752 - val_loss: 1.8337 - val_accuracy: 0.6898 - 17s/epoch - 459ms/step\n",
      "Epoch 95/150\n",
      "38/38 - 17s - loss: 0.1382 - accuracy: 0.9677 - val_loss: 1.7613 - val_accuracy: 0.6535 - 17s/epoch - 459ms/step\n",
      "Epoch 96/150\n",
      "38/38 - 17s - loss: 0.1114 - accuracy: 0.9653 - val_loss: 2.5127 - val_accuracy: 0.6436 - 17s/epoch - 459ms/step\n",
      "Epoch 97/150\n",
      "38/38 - 17s - loss: 0.1731 - accuracy: 0.9495 - val_loss: 3.5299 - val_accuracy: 0.5578 - 17s/epoch - 459ms/step\n",
      "Epoch 98/150\n",
      "38/38 - 17s - loss: 0.1756 - accuracy: 0.9595 - val_loss: 2.8609 - val_accuracy: 0.5611 - 17s/epoch - 460ms/step\n",
      "Epoch 99/150\n",
      "38/38 - 17s - loss: 0.1236 - accuracy: 0.9628 - val_loss: 2.4710 - val_accuracy: 0.6271 - 17s/epoch - 458ms/step\n",
      "Epoch 100/150\n",
      "38/38 - 17s - loss: 0.1510 - accuracy: 0.9578 - val_loss: 2.0051 - val_accuracy: 0.6601 - 17s/epoch - 459ms/step\n",
      "Epoch 101/150\n",
      "38/38 - 17s - loss: 0.1242 - accuracy: 0.9636 - val_loss: 2.4043 - val_accuracy: 0.6337 - 17s/epoch - 458ms/step\n",
      "Epoch 102/150\n",
      "38/38 - 17s - loss: 0.1241 - accuracy: 0.9677 - val_loss: 2.2562 - val_accuracy: 0.6370 - 17s/epoch - 459ms/step\n",
      "Epoch 103/150\n",
      "38/38 - 17s - loss: 0.1197 - accuracy: 0.9628 - val_loss: 1.9958 - val_accuracy: 0.6568 - 17s/epoch - 459ms/step\n",
      "Epoch 104/150\n",
      "38/38 - 17s - loss: 0.1211 - accuracy: 0.9636 - val_loss: 2.5394 - val_accuracy: 0.6502 - 17s/epoch - 459ms/step\n",
      "Epoch 105/150\n",
      "38/38 - 17s - loss: 0.0907 - accuracy: 0.9752 - val_loss: 2.2863 - val_accuracy: 0.6634 - 17s/epoch - 459ms/step\n",
      "Epoch 106/150\n",
      "38/38 - 17s - loss: 0.0937 - accuracy: 0.9752 - val_loss: 2.1185 - val_accuracy: 0.6469 - 17s/epoch - 458ms/step\n",
      "Epoch 107/150\n",
      "38/38 - 17s - loss: 0.0949 - accuracy: 0.9711 - val_loss: 2.0653 - val_accuracy: 0.6964 - 17s/epoch - 459ms/step\n",
      "Epoch 108/150\n",
      "38/38 - 17s - loss: 0.1528 - accuracy: 0.9578 - val_loss: 1.8403 - val_accuracy: 0.6469 - 17s/epoch - 459ms/step\n",
      "Epoch 109/150\n",
      "38/38 - 17s - loss: 0.1660 - accuracy: 0.9636 - val_loss: 2.0499 - val_accuracy: 0.6403 - 17s/epoch - 459ms/step\n",
      "Epoch 110/150\n",
      "38/38 - 17s - loss: 0.1207 - accuracy: 0.9686 - val_loss: 2.2949 - val_accuracy: 0.6469 - 17s/epoch - 459ms/step\n",
      "Epoch 111/150\n",
      "38/38 - 17s - loss: 0.1452 - accuracy: 0.9553 - val_loss: 1.8019 - val_accuracy: 0.6766 - 17s/epoch - 459ms/step\n",
      "Epoch 112/150\n",
      "38/38 - 17s - loss: 0.1190 - accuracy: 0.9653 - val_loss: 3.4622 - val_accuracy: 0.5809 - 17s/epoch - 460ms/step\n",
      "Epoch 113/150\n",
      "38/38 - 17s - loss: 0.1005 - accuracy: 0.9760 - val_loss: 1.7429 - val_accuracy: 0.6997 - 17s/epoch - 459ms/step\n",
      "Epoch 114/150\n",
      "38/38 - 17s - loss: 0.1100 - accuracy: 0.9735 - val_loss: 1.7894 - val_accuracy: 0.6931 - 17s/epoch - 459ms/step\n",
      "Epoch 115/150\n",
      "38/38 - 17s - loss: 0.0949 - accuracy: 0.9727 - val_loss: 2.1981 - val_accuracy: 0.6766 - 17s/epoch - 459ms/step\n",
      "Epoch 116/150\n",
      "38/38 - 17s - loss: 0.1954 - accuracy: 0.9413 - val_loss: 2.2571 - val_accuracy: 0.6535 - 17s/epoch - 459ms/step\n",
      "Epoch 117/150\n",
      "38/38 - 17s - loss: 0.1028 - accuracy: 0.9694 - val_loss: 2.3916 - val_accuracy: 0.6436 - 17s/epoch - 459ms/step\n",
      "Epoch 118/150\n",
      "38/38 - 17s - loss: 0.2338 - accuracy: 0.9404 - val_loss: 2.2309 - val_accuracy: 0.5545 - 17s/epoch - 458ms/step\n",
      "Epoch 119/150\n",
      "38/38 - 17s - loss: 0.1525 - accuracy: 0.9545 - val_loss: 1.7799 - val_accuracy: 0.6568 - 17s/epoch - 458ms/step\n",
      "Epoch 120/150\n",
      "38/38 - 17s - loss: 0.1135 - accuracy: 0.9677 - val_loss: 2.2656 - val_accuracy: 0.6436 - 17s/epoch - 458ms/step\n",
      "Epoch 121/150\n",
      "38/38 - 17s - loss: 0.0840 - accuracy: 0.9727 - val_loss: 2.3900 - val_accuracy: 0.6403 - 17s/epoch - 459ms/step\n",
      "Epoch 122/150\n",
      "38/38 - 17s - loss: 0.0835 - accuracy: 0.9744 - val_loss: 2.1788 - val_accuracy: 0.6403 - 17s/epoch - 458ms/step\n",
      "Epoch 123/150\n",
      "38/38 - 17s - loss: 0.0770 - accuracy: 0.9702 - val_loss: 2.0738 - val_accuracy: 0.6766 - 17s/epoch - 459ms/step\n",
      "Epoch 124/150\n",
      "38/38 - 17s - loss: 0.0865 - accuracy: 0.9727 - val_loss: 2.0978 - val_accuracy: 0.6700 - 17s/epoch - 459ms/step\n",
      "Epoch 125/150\n",
      "38/38 - 17s - loss: 0.0872 - accuracy: 0.9793 - val_loss: 2.1371 - val_accuracy: 0.6370 - 17s/epoch - 458ms/step\n",
      "Epoch 126/150\n",
      "38/38 - 17s - loss: 0.1258 - accuracy: 0.9694 - val_loss: 1.6843 - val_accuracy: 0.6865 - 17s/epoch - 459ms/step\n",
      "Epoch 127/150\n",
      "38/38 - 17s - loss: 0.0485 - accuracy: 0.9843 - val_loss: 1.6542 - val_accuracy: 0.7129 - 17s/epoch - 458ms/step\n",
      "Epoch 128/150\n",
      "38/38 - 17s - loss: 0.0661 - accuracy: 0.9826 - val_loss: 2.3291 - val_accuracy: 0.6238 - 17s/epoch - 458ms/step\n",
      "Epoch 129/150\n",
      "38/38 - 17s - loss: 0.0836 - accuracy: 0.9760 - val_loss: 1.6948 - val_accuracy: 0.6865 - 17s/epoch - 458ms/step\n",
      "Epoch 130/150\n",
      "38/38 - 17s - loss: 0.0628 - accuracy: 0.9818 - val_loss: 1.7789 - val_accuracy: 0.7063 - 17s/epoch - 458ms/step\n",
      "Epoch 131/150\n",
      "38/38 - 17s - loss: 0.0466 - accuracy: 0.9859 - val_loss: 1.7228 - val_accuracy: 0.7195 - 17s/epoch - 459ms/step\n",
      "Epoch 132/150\n",
      "38/38 - 17s - loss: 0.0480 - accuracy: 0.9868 - val_loss: 1.8996 - val_accuracy: 0.7459 - 17s/epoch - 458ms/step\n",
      "Epoch 133/150\n",
      "38/38 - 17s - loss: 0.0917 - accuracy: 0.9785 - val_loss: 1.9112 - val_accuracy: 0.7063 - 17s/epoch - 459ms/step\n",
      "Epoch 134/150\n",
      "38/38 - 17s - loss: 0.1004 - accuracy: 0.9777 - val_loss: 2.1378 - val_accuracy: 0.6634 - 17s/epoch - 458ms/step\n",
      "Epoch 135/150\n",
      "38/38 - 17s - loss: 0.1164 - accuracy: 0.9785 - val_loss: 2.6640 - val_accuracy: 0.6139 - 17s/epoch - 459ms/step\n",
      "Epoch 136/150\n",
      "38/38 - 17s - loss: 0.1650 - accuracy: 0.9570 - val_loss: 1.8581 - val_accuracy: 0.6469 - 17s/epoch - 459ms/step\n",
      "Epoch 137/150\n",
      "38/38 - 17s - loss: 0.1901 - accuracy: 0.9454 - val_loss: 2.8119 - val_accuracy: 0.6073 - 17s/epoch - 458ms/step\n",
      "Epoch 138/150\n",
      "38/38 - 17s - loss: 0.1298 - accuracy: 0.9628 - val_loss: 2.2419 - val_accuracy: 0.6502 - 17s/epoch - 458ms/step\n",
      "Epoch 139/150\n",
      "38/38 - 17s - loss: 0.1066 - accuracy: 0.9694 - val_loss: 2.2214 - val_accuracy: 0.6370 - 17s/epoch - 458ms/step\n",
      "Epoch 140/150\n",
      "38/38 - 17s - loss: 0.1166 - accuracy: 0.9719 - val_loss: 1.8283 - val_accuracy: 0.6502 - 17s/epoch - 460ms/step\n",
      "Epoch 141/150\n",
      "38/38 - 17s - loss: 0.0923 - accuracy: 0.9768 - val_loss: 1.7015 - val_accuracy: 0.7294 - 17s/epoch - 459ms/step\n",
      "Epoch 142/150\n",
      "38/38 - 17s - loss: 0.1164 - accuracy: 0.9636 - val_loss: 1.8758 - val_accuracy: 0.6271 - 17s/epoch - 458ms/step\n",
      "Epoch 143/150\n",
      "38/38 - 17s - loss: 0.1052 - accuracy: 0.9661 - val_loss: 2.1456 - val_accuracy: 0.6436 - 17s/epoch - 459ms/step\n",
      "Epoch 144/150\n",
      "38/38 - 17s - loss: 0.1157 - accuracy: 0.9636 - val_loss: 1.8619 - val_accuracy: 0.6502 - 17s/epoch - 458ms/step\n",
      "Epoch 145/150\n",
      "38/38 - 17s - loss: 0.0941 - accuracy: 0.9777 - val_loss: 1.7223 - val_accuracy: 0.6997 - 17s/epoch - 459ms/step\n",
      "Epoch 146/150\n",
      "38/38 - 17s - loss: 0.0873 - accuracy: 0.9801 - val_loss: 1.9651 - val_accuracy: 0.6502 - 17s/epoch - 458ms/step\n",
      "Epoch 147/150\n",
      "38/38 - 17s - loss: 0.0898 - accuracy: 0.9752 - val_loss: 1.7742 - val_accuracy: 0.6865 - 17s/epoch - 458ms/step\n",
      "Epoch 148/150\n",
      "38/38 - 17s - loss: 0.0705 - accuracy: 0.9826 - val_loss: 2.3277 - val_accuracy: 0.6370 - 17s/epoch - 458ms/step\n",
      "Epoch 149/150\n",
      "38/38 - 17s - loss: 0.0754 - accuracy: 0.9826 - val_loss: 1.8918 - val_accuracy: 0.6898 - 17s/epoch - 459ms/step\n",
      "Epoch 150/150\n",
      "38/38 - 17s - loss: 0.0999 - accuracy: 0.9694 - val_loss: 1.9110 - val_accuracy: 0.7228 - 17s/epoch - 459ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd54a483c90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For earlystopping we need to validation dataset\n",
    "base_model.fit(X_train, y_train, epochs=150, validation_split=0.20, verbose=2, callbacks=[callback], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxQhxqL37Owd",
    "outputId": "549aac49-18d4-4683-fffa-86fbd0dcb9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 3s 136ms/step - loss: 1.6139 - accuracy: 0.7257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6139328479766846, 0.7257319092750549]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "InK32bC4EB4D"
   },
   "outputs": [],
   "source": [
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "x03xZcd_vIkT"
   },
   "outputs": [],
   "source": [
    "y_predicted = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "815IAgkkvZFQ",
    "outputId": "ab581174-343f-4a18-b5d7-e41f7c7cf828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75         5\n",
      "           1       0.69      0.75      0.72        12\n",
      "           2       0.78      0.70      0.74        20\n",
      "           3       0.75      0.75      0.75         4\n",
      "           4       0.69      0.82      0.75        22\n",
      "           5       0.86      1.00      0.92         6\n",
      "           6       0.80      0.52      0.63        23\n",
      "           7       0.80      0.84      0.82        19\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       1.00      0.20      0.33         5\n",
      "          10       0.83      0.79      0.81        19\n",
      "          11       0.52      0.75      0.62        16\n",
      "          12       0.87      0.68      0.76        19\n",
      "          13       0.82      0.64      0.72        22\n",
      "          14       0.67      0.57      0.62        21\n",
      "          15       1.00      0.50      0.67         4\n",
      "          16       0.77      0.93      0.84        29\n",
      "          17       0.94      0.62      0.75        24\n",
      "          18       0.65      0.71      0.68        24\n",
      "          19       0.94      0.76      0.84        21\n",
      "          20       0.67      0.83      0.74        24\n",
      "          21       1.00      0.60      0.75        25\n",
      "          22       0.75      0.83      0.79        18\n",
      "          23       0.94      0.75      0.83        20\n",
      "          24       0.64      0.76      0.70        21\n",
      "          25       0.70      0.67      0.68        21\n",
      "          26       0.58      0.95      0.72        22\n",
      "          27       0.60      0.90      0.72        29\n",
      "          28       0.56      0.79      0.65        19\n",
      "          29       0.75      0.69      0.72        26\n",
      "          30       0.83      0.75      0.79        20\n",
      "          31       0.82      0.67      0.74        21\n",
      "          32       1.00      0.54      0.70        13\n",
      "          33       1.00      0.25      0.40         4\n",
      "          34       1.00      0.43      0.60         7\n",
      "          35       0.79      0.68      0.73        22\n",
      "          36       0.47      0.89      0.62        18\n",
      "\n",
      "    accuracy                           0.73       649\n",
      "   macro avg       0.77      0.68      0.69       649\n",
      "weighted avg       0.76      0.73      0.72       649\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_to_check, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
